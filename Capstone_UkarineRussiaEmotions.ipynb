{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWt_--wFlATZ",
        "outputId": "9a9a52e0-ae68-4ca9-d6de-b5c8abb1fc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cIYg8XBSK-yIwMayCIVsz4FeUCKfZHlJ\n",
            "To: /content/EmoticonHuggingFace.csv.zip\n",
            "100% 29.3M/29.3M [00:00<00:00, 105MB/s] \n"
          ]
        }
      ],
      "source": [
        "!gdown 1cIYg8XBSK-yIwMayCIVsz4FeUCKfZHlJ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip EmoticonHuggingFace.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ71aX2ClONk",
        "outputId": "01bdcbc6-bb48-4933-be10-85c01309e0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  EmoticonHuggingFace.csv.zip\n",
            "  inflating: EmoticonHuggingFace.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "bUM4wpTUlP2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('EmoticonHuggingFace.csv')"
      ],
      "metadata": {
        "id": "oz62r7qNlRUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "YlpqwLqplS4k",
        "outputId": "30abeb04-0eb2-458f-e771-4264637d0358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0.4  Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
              "0                  0             0             0             0           0   \n",
              "1                  1             1             1             1           1   \n",
              "2                  2             2             2             2           2   \n",
              "3                  3             3             3             3           3   \n",
              "4                  4             4             4             4           4   \n",
              "...              ...           ...           ...           ...         ...   \n",
              "247486        247486        672114        672114        672114      190910   \n",
              "247487        247487        672115        672115        672115      190911   \n",
              "247488        247488        672120        672120        672120      190916   \n",
              "247489        247489        672121        672121        672121      190917   \n",
              "247490        247490        672124        672124        672124      190920   \n",
              "\n",
              "                                                        0  \\\n",
              "0       #tfiglobal geopolitics aug #macron  legitimise...   \n",
              "1       🇺🇦🇷🇺⚡the armed forces of ukraine attacked the ...   \n",
              "2       @kminorschneider @miriam @scottuhltx 😥 🇺🇦 help...   \n",
              "3       darya dugina daughter of “putin’s brain” alexa...   \n",
              "4       @huxijin_gt i knew u don't know the proper wor...   \n",
              "...                                                   ...   \n",
              "247486  time to stop the war 🙏 #timepoy #ukraine @time...   \n",
              "247487  beautiful goosebumps man maaaaaximum aquarius ...   \n",
              "247488  need company to finish your morning porridge b...   \n",
              "247489  please do something if you can for us we are h...   \n",
              "247490  for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...   \n",
              "\n",
              "                                                     Text  \\\n",
              "0       geopolitics aug legitimises controlover ⁉️fran...   \n",
              "1       🇺🇦🇷🇺⚡the armed forces of ukraine attacked the ...   \n",
              "2       😥 🇺🇦 help stop putin at president zelensky s 🌍...   \n",
              "3       darya dugina daughter of “putin’s brain” alexa...   \n",
              "4       gt i knew you don t know the proper word for s...   \n",
              "...                                                   ...   \n",
              "247486         time to stop the war 🙏 zelenska tv ukraine   \n",
              "247487  beautiful goosebumps man maaaaaximum aquarius ...   \n",
              "247488  need company to finish your morning porridge b...   \n",
              "247489  please do something if you can for us we are h...   \n",
              "247490  for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...   \n",
              "\n",
              "                                            LemmatizeText HuggingFaceEmoticon  \n",
              "0       geopolitics aug legitimises controlover ⁉️fran...           amusement  \n",
              "1       🇺🇦🇷🇺⚡the armed force of ukraine attacked the n...             neutral  \n",
              "2       😥 🇺🇦 help stop putin at president zelensky s 🌍...            approval  \n",
              "3       darya dugina daughter of “putin’s brain” alexa...             neutral  \n",
              "4       gt i knew you don t know the proper word for s...             neutral  \n",
              "...                                                   ...                 ...  \n",
              "247486         time to stop the war 🙏 zelenska tv ukraine             neutral  \n",
              "247487  beautiful goosebump man maaaaaximum aquarius ♒...          admiration  \n",
              "247488  need company to finish your morning porridge b...              desire  \n",
              "247489  please do something if you can for u we are ho...              desire  \n",
              "247490  for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...             neutral  \n",
              "\n",
              "[247491 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8c8a41b-a449-440b-9028-4e35fee36bf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.4</th>\n",
              "      <th>Unnamed: 0.3</th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>Text</th>\n",
              "      <th>LemmatizeText</th>\n",
              "      <th>HuggingFaceEmoticon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>#tfiglobal geopolitics aug #macron  legitimise...</td>\n",
              "      <td>geopolitics aug legitimises controlover ⁉️fran...</td>\n",
              "      <td>geopolitics aug legitimises controlover ⁉️fran...</td>\n",
              "      <td>amusement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>🇺🇦🇷🇺⚡the armed forces of ukraine attacked the ...</td>\n",
              "      <td>🇺🇦🇷🇺⚡the armed forces of ukraine attacked the ...</td>\n",
              "      <td>🇺🇦🇷🇺⚡the armed force of ukraine attacked the n...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>@kminorschneider @miriam @scottuhltx 😥 🇺🇦 help...</td>\n",
              "      <td>😥 🇺🇦 help stop putin at president zelensky s 🌍...</td>\n",
              "      <td>😥 🇺🇦 help stop putin at president zelensky s 🌍...</td>\n",
              "      <td>approval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>darya dugina daughter of “putin’s brain” alexa...</td>\n",
              "      <td>darya dugina daughter of “putin’s brain” alexa...</td>\n",
              "      <td>darya dugina daughter of “putin’s brain” alexa...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>@huxijin_gt i knew u don't know the proper wor...</td>\n",
              "      <td>gt i knew you don t know the proper word for s...</td>\n",
              "      <td>gt i knew you don t know the proper word for s...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247486</th>\n",
              "      <td>247486</td>\n",
              "      <td>672114</td>\n",
              "      <td>672114</td>\n",
              "      <td>672114</td>\n",
              "      <td>190910</td>\n",
              "      <td>time to stop the war 🙏 #timepoy #ukraine @time...</td>\n",
              "      <td>time to stop the war 🙏 zelenska tv ukraine</td>\n",
              "      <td>time to stop the war 🙏 zelenska tv ukraine</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247487</th>\n",
              "      <td>247487</td>\n",
              "      <td>672115</td>\n",
              "      <td>672115</td>\n",
              "      <td>672115</td>\n",
              "      <td>190911</td>\n",
              "      <td>beautiful goosebumps man maaaaaximum aquarius ...</td>\n",
              "      <td>beautiful goosebumps man maaaaaximum aquarius ...</td>\n",
              "      <td>beautiful goosebump man maaaaaximum aquarius ♒...</td>\n",
              "      <td>admiration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247488</th>\n",
              "      <td>247488</td>\n",
              "      <td>672120</td>\n",
              "      <td>672120</td>\n",
              "      <td>672120</td>\n",
              "      <td>190916</td>\n",
              "      <td>need company to finish your morning porridge b...</td>\n",
              "      <td>need company to finish your morning porridge b...</td>\n",
              "      <td>need company to finish your morning porridge b...</td>\n",
              "      <td>desire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247489</th>\n",
              "      <td>247489</td>\n",
              "      <td>672121</td>\n",
              "      <td>672121</td>\n",
              "      <td>672121</td>\n",
              "      <td>190917</td>\n",
              "      <td>please do something if you can for us we are h...</td>\n",
              "      <td>please do something if you can for us we are h...</td>\n",
              "      <td>please do something if you can for u we are ho...</td>\n",
              "      <td>desire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247490</th>\n",
              "      <td>247490</td>\n",
              "      <td>672124</td>\n",
              "      <td>672124</td>\n",
              "      <td>672124</td>\n",
              "      <td>190920</td>\n",
              "      <td>for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...</td>\n",
              "      <td>for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...</td>\n",
              "      <td>for iranian women✌🏻🙋🏻‍♀️great heroes❤️#womanli...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>247491 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8c8a41b-a449-440b-9028-4e35fee36bf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8c8a41b-a449-440b-9028-4e35fee36bf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8c8a41b-a449-440b-9028-4e35fee36bf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38c369b2-5804-4b32-accc-fb54028a9ed4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38c369b2-5804-4b32-accc-fb54028a9ed4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38c369b2-5804-4b32-accc-fb54028a9ed4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_22d4dc84-c59a-4699-8b9d-1110d9ab62ae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_22d4dc84-c59a-4699-8b9d-1110d9ab62ae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = ['Unnamed: 0.4',\t'Unnamed: 0.3',\t'Unnamed: 0.2',\t'Unnamed: 0.1',\t'Unnamed: 0'\t,'0',\t'Text']\n",
        "\n",
        "# Remove the specified columns\n",
        "df = df.drop(columns=columns_to_remove)"
      ],
      "metadata": {
        "id": "uJQOStqmlUrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_count = df['HuggingFaceEmoticon'].nunique()\n",
        "print(\"Number of unique values:\", unique_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TxvD5RwlYMY",
        "outputId": "2f1b6fbc-0888-4a91-f152-e2ebf4c64620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_counts = df['HuggingFaceEmoticon'].value_counts()"
      ],
      "metadata": {
        "id": "GaqVJrUsla7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSo_ntnglcww",
        "outputId": "203db9f7-d363-47fd-a970-641f5e83bb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral           146773\n",
              "approval           11722\n",
              "caring             11400\n",
              "gratitude          10551\n",
              "admiration         10225\n",
              "sadness             9399\n",
              "love                7758\n",
              "optimism            6418\n",
              "curiosity           4272\n",
              "amusement           3818\n",
              "disapproval         3291\n",
              "annoyance           3243\n",
              "disappointment      3016\n",
              "anger               2467\n",
              "joy                 2145\n",
              "fear                2131\n",
              "desire              2123\n",
              "excitement          1357\n",
              "surprise            1338\n",
              "confusion           1194\n",
              "disgust              804\n",
              "remorse              669\n",
              "realization          623\n",
              "embarrassment        518\n",
              "nervousness          135\n",
              "pride                 98\n",
              "relief                 3\n",
              "Name: HuggingFaceEmoticon, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GvV8Tqrxlehq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.LemmatizeText\n",
        "y=df.HuggingFaceEmoticon"
      ],
      "metadata": {
        "id": "O5DS8vY8l86a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Conv1D, MaxPooling1D, Flatten, concatenate, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming you have your text data and corresponding labels in X_train_text, X_test_text, y_train, and y_test\n",
        "\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "\n",
        "# Tokenize and pad your text data\n",
        "max_sequence_length = 100  # adjust based on your data\n",
        "vocab_size = 10000  # adjust based on your data\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model 1: Bidirectional LSTM\n",
        "input_lstm = Input(shape=(max_sequence_length,))\n",
        "embedding_lstm = Embedding(input_dim=vocab_size, output_dim=100)(input_lstm)\n",
        "lstm_out = Bidirectional(LSTM(64))(embedding_lstm)\n",
        "\n",
        "# Model 2: Convolutional Neural Network (CNN)\n",
        "input_cnn = Input(shape=(max_sequence_length,))\n",
        "embedding_cnn = Embedding(input_dim=vocab_size, output_dim=100)(input_cnn)\n",
        "conv1d_out = Conv1D(64, 3, activation='relu')(embedding_cnn)\n",
        "pooling_out = MaxPooling1D(pool_size=4)(conv1d_out)\n",
        "flatten_cnn = Flatten()(pooling_out)\n",
        "\n",
        "# # Model 3: Support Vector Machine (SVM)\n",
        "# svm_model = SVC(probability=True)  # probability=True allows us to use decision function output\n",
        "# svm_model.fit(X_train_padded, y_train_encoded)\n",
        "# svm_output = svm_model.decision_function(X_train_padded)  # use decision function as input\n",
        "\n",
        "# Merge models\n",
        "merged = concatenate([lstm_out, flatten_cnn])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[input_lstm, input_cnn], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([X_train_padded, X_train_padded, svm_output], y_train_one_hot, epochs=2, batch_size=100, validation_data=([X_test_padded, X_test_padded, svm_model.decision_function(X_test_padded)], y_test_one_hot))\n"
      ],
      "metadata": {
        "id": "uNEGKueNlhLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# Enable NumPy behavior in TensorFlow\n",
        "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
        "\n",
        "# Assuming you have your text data and corresponding labels in X_train_text, X_test_text, y_train, and y_test\n",
        "\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "\n",
        "# Tokenize and pad your text data using BERT tokenizer\n",
        "max_sequence_length = 100  # adjust based on your data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and pad the training data\n",
        "X_train_encoded = tokenizer(X_train_text.tolist(), truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
        "X_test_encoded = tokenizer(X_test_text.tolist(), truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
        "\n",
        "# Define vocab_size (the number of unique words in your training data)\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model 1: Bidirectional LSTM\n",
        "input_lstm = Input(shape=(max_sequence_length,))\n",
        "embedding_lstm = Embedding(input_dim=vocab_size, output_dim=100)(input_lstm)\n",
        "lstm_out = Bidirectional(LSTM(64))(embedding_lstm)\n",
        "\n",
        "# Model 2: BERT\n",
        "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "bert_output = bert_model(input_ids=X_train_encoded['input_ids'], attention_mask=X_train_encoded['attention_mask']).pooler_output\n",
        "\n",
        "# Merge models\n",
        "merged = Concatenate()([lstm_out, bert_output])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[input_lstm, bert_model.input['input_ids'], bert_model.input['attention_mask']], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([X_train_padded, X_train_encoded['input_ids'], X_train_encoded['attention_mask']], y_train_one_hot, epochs=2, batch_size=100, validation_data=([X_test_padded, X_test_encoded['input_ids'], X_test_encoded['attention_mask']], y_test_one_hot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "FhR0IKXd-K-Z",
        "outputId": "8f215f66-3a22-440c-bc43-c43f2224695f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-26c2dc612fcf>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Extract BERT embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Merge models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract BERT embeddings\n",
        "bert_output = bert_model(input_ids=X_train_encoded['input_ids'], attention_mask=X_train_encoded['attention_mask']).pooler_output\n",
        "\n",
        "# Merge models\n",
        "merged = Concatenate()([lstm_out, bert_output])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[input_lstm, bert_model.input['input_ids'], bert_model.input['attention_mask']], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([X_train_padded, X_train_encoded['input_ids'], X_train_encoded['attention_mask']], y_train_one_hot, epochs=2, batch_size=100, validation_data=([X_test_padded, X_test_encoded['input_ids'], X_test_encoded['attention_mask']], y_test_one_hot))\n"
      ],
      "metadata": {
        "id": "YjfBYmvyAzeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN and SVC**"
      ],
      "metadata": {
        "id": "2ric2pq-XBVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, concatenate, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming you have your text data and corresponding labels in X_train_text, X_test_text, y_train, and y_test\n",
        "\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "\n",
        "# Tokenize and pad your text data\n",
        "max_sequence_length = 100  # adjust based on your data\n",
        "vocab_size = 10000  # adjust based on your data\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model 2: Convolutional Neural Network (CNN)\n",
        "input_cnn = Input(shape=(max_sequence_length,))\n",
        "embedding_cnn = Embedding(input_dim=vocab_size, output_dim=100)(input_cnn)\n",
        "conv1d_out = Conv1D(64, 3, activation='relu')(embedding_cnn)\n",
        "pooling_out = MaxPooling1D(pool_size=4)(conv1d_out)\n",
        "flatten_cnn = Flatten()(pooling_out)\n",
        "\n",
        "# Model 3: Support Vector Machine (SVM)\n",
        "svm_model = SVC(probability=True)  # probability=True allows us to use decision function output\n",
        "svm_model.fit(X_train_padded, y_train_encoded)\n",
        "svm_output = svm_model.decision_function(X_train_padded)  # use decision function as input\n",
        "\n",
        "# Merge models\n",
        "merged = concatenate([flatten_cnn, svm_output])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[input_cnn, svm_output], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([X_train_padded, svm_output], y_train_one_hot, epochs=2, batch_size=100, validation_data=([X_test_padded, svm_model.decision_function(X_test_padded)], y_test_one_hot))\n"
      ],
      "metadata": {
        "id": "dZdMAmkElm6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming you have your text data and corresponding labels in X_train_text, X_test_text, y_train, and y_test\n",
        "\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "\n",
        "# Tokenize and pad your text data\n",
        "max_sequence_length = 100  # adjust based on your data\n",
        "vocab_size = 10000  # adjust based on your data\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model 1: Support Vector Machine (SVM)\n",
        "svm_model = SVC(probability=True)  # probability=True allows us to use decision function output\n",
        "svm_model.fit(X_train_padded, y_train_encoded)\n",
        "svm_output = svm_model.decision_function(X_train_padded)  # use decision function as input\n",
        "\n",
        "# Model 2: Principal Component Analysis (PCA)\n",
        "pca = PCA(n_components=10)  # adjust the number of components based on your data\n",
        "X_train_pca = pca.fit_transform(X_train_padded)\n",
        "X_test_pca = pca.transform(X_test_padded)\n",
        "\n",
        "# Merge models\n",
        "merged = concatenate([svm_output, X_train_pca])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[svm_output, X_train_pca], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([svm_output, X_train_pca], y_train_one_hot, epochs=2, batch_size=100, validation_data=([svm_model.decision_function(X_test_padded), X_test_pca], y_test_one_hot))\n"
      ],
      "metadata": {
        "id": "mMsHMC05XViR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, concatenate, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Assuming you have your text data and corresponding labels in X_train_text, X_test_text, y_train, and y_test\n",
        "\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "\n",
        "# Tokenize and pad your text data using BERT tokenizer\n",
        "max_sequence_length = 100  # adjust based on your data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and pad the training data\n",
        "X_train_encoded = tokenizer(X_train_text, truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
        "\n",
        "# Tokenize and pad the testing data\n",
        "X_test_encoded = tokenizer(X_test_text, truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
        "\n",
        "# Model 2: Convolutional Neural Network (CNN)\n",
        "input_cnn = Input(shape=(max_sequence_length,))\n",
        "embedding_cnn = Embedding(input_dim=vocab_size, output_dim=100)(input_cnn)\n",
        "conv1d_out = Conv1D(64, 3, activation='relu')(embedding_cnn)\n",
        "pooling_out = MaxPooling1D(pool_size=4)(conv1d_out)\n",
        "flatten_cnn = Flatten()(pooling_out)\n",
        "\n",
        "# Model 3: BERT\n",
        "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "bert_output = bert_model(input_ids=X_train_encoded['input_ids'], attention_mask=X_train_encoded['attention_mask']).pooler_output\n",
        "\n",
        "# Merge models\n",
        "merged = concatenate([flatten_cnn, bert_output])\n",
        "\n",
        "# Common Dense layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=[input_cnn, bert_model.input['input_ids'], bert_model.input['attention_mask']], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ensemble_model.fit([X_train_padded, X_train_encoded['input_ids'], X_train_encoded['attention_mask']], y_train_one_hot, epochs=2, batch_size=100, validation_data=([X_test_padded, X_test_encoded['input_ids'], X_test_encoded['attention_mask']], y_test_one_hot))\n"
      ],
      "metadata": {
        "id": "c6HCIGL0srS4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "deb180cb-d962-40ba-a75d-2b48bfea0ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c7df6fb35b37>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Tokenize and pad the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Tokenize and pad the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2796\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2798\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2856\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2857\u001b[0m                 \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZhPV3gP8whw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}